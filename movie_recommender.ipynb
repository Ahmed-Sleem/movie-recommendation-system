{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#prerun"
      ],
      "metadata": {
        "id": "NxiQ18FAOQeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics.pairwise import linear_kernel"
      ],
      "metadata": {
        "id": "gZQ2bPFsKCWT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#experimental"
      ],
      "metadata": {
        "id": "_t4-bd59OSks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"imdb_top_1000.csv\")"
      ],
      "metadata": {
        "id": "Y9hQ20TMKIVF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#del unneeded\n",
        "cols=[\"Poster_Link\",\"Certificate\",\"Meta_score\",\"Gross\" ]\n",
        "data = data.drop(columns=cols)\n",
        "\n",
        "# Handle missing values (if any)\n",
        "data = data.dropna()\n"
      ],
      "metadata": {
        "id": "dd09-o8EKY4u"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Runtime' to numerical (e.g., \"142 min\" to 142)\n",
        "data['Runtime'] = data['Runtime'].str.replace(' min', '').astype(int)\n",
        "\n",
        "# Combine the features into a single string for simplicity (e.g., genre, director, stars)\n",
        "data['combined_features'] = data.apply(lambda row: f\"{row['Genre']} {row['Director']} {row['Star1']} {row['Star2']} {row['Star3']} {row['Star4']}\", axis=1)"
      ],
      "metadata": {
        "id": "XwL6XEpCKThD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Fit and transform the data\n",
        "tfidf_matrix = tfidf.fit_transform(data['combined_features'])"
      ],
      "metadata": {
        "id": "toPP1x5zLwCi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the cosine similarity matrix\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
      ],
      "metadata": {
        "id": "e3dCnvPNMF11"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping of movie titles to indices\n",
        "indices = pd.Series(data.index, index=data['Series_Title']).drop_duplicates()\n",
        "\n",
        "def get_recommendations(title, cosine_sim=cosine_sim):\n",
        "    # Get the index of the movie that matches the title\n",
        "    idx = indices[title]\n",
        "\n",
        "    # Get the pairwise similarity scores of all movies with that movie\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # Sort the movies based on the similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the 10 most similar movies\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # Get the movie indices\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Return the top 10 most similar movies\n",
        "    return data['Series_Title'].iloc[movie_indices]\n"
      ],
      "metadata": {
        "id": "tO8Xrs5qMSDE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weighted_recommendations(ratings, cosine_sim=cosine_sim):\n",
        "    total_sim_scores = {}\n",
        "\n",
        "    for movie, rating in ratings.items():\n",
        "        # Get the index of the movie that matches the title\n",
        "        idx = indices[movie]\n",
        "\n",
        "        # Get the pairwise similarity scores of all movies with that movie\n",
        "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "        for i, score in sim_scores:\n",
        "            if i in total_sim_scores:\n",
        "                total_sim_scores[i] += score * rating\n",
        "            else:\n",
        "                total_sim_scores[i] = score * rating\n",
        "\n",
        "    # Sort the movies based on the weighted similarity scores\n",
        "    sorted_sim_scores = sorted(total_sim_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the movie indices of the top recommendations, excluding already rated movies\n",
        "    recommended_movie_indices = [i[0] for i in sorted_sim_scores if data['Series_Title'].iloc[i[0]] not in ratings][:10]\n",
        "\n",
        "    # Return the top 10 recommendations\n",
        "    return data['Series_Title'].iloc[recommended_movie_indices]\n"
      ],
      "metadata": {
        "id": "_AVX-u2vMTiv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you have a dictionary of personal ratings\n",
        "personal_ratings = {\n",
        "    'The Shawshank Redemption': 9,\n",
        "    'Inception': 10,\n",
        "    'The Dark Knight': 0.5,\n",
        "    'Dunkirk':0,\n",
        "    'The Prestige':8\n",
        "}\n",
        "# Get recommendations based on your personal ratings\n",
        "recommendations = get_weighted_recommendations(personal_ratings)\n",
        "print(recommendations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZJsEjadMdij",
        "outputId": "85a6e662-e701-469f-e397-a57c3b411ae4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155                          Batman Begins\n",
            "63                   The Dark Knight Rises\n",
            "21                            Interstellar\n",
            "479             X-Men: Days of Future Past\n",
            "202                                  Logan\n",
            "357                           The Avengers\n",
            "675             Back to the Future Part II\n",
            "737    Captain America: The Winter Soldier\n",
            "583             Captain America: Civil War\n",
            "243                    Catch Me If You Can\n",
            "Name: Series_Title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#OOP"
      ],
      "metadata": {
        "id": "qo-1KR6aNVSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "import pickle\n",
        "\n",
        "class MovieRecommender:\n",
        "    def __init__(self, data_file=None):\n",
        "        if data_file:\n",
        "            self.data = pd.read_csv(data_file)\n",
        "            self._preprocess_data()\n",
        "            self._create_tfidf_matrix()\n",
        "        else:\n",
        "            self.data = None\n",
        "            self.tfidf_matrix = None\n",
        "            self.cosine_sim = None\n",
        "            self.indices = None\n",
        "\n",
        "    def _preprocess_data(self):\n",
        "\n",
        "        try:\n",
        "          # Delete unneeded columns\n",
        "          cols = [\"Poster_Link\", \"Certificate\", \"Meta_score\", \"Gross\"]\n",
        "          self.data = self.data.drop(columns=cols)\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "        # Handle missing values\n",
        "        self.data = self.data.dropna()\n",
        "\n",
        "        # Convert 'Runtime' to numerical\n",
        "        self.data['Runtime'] = self.data['Runtime'].str.replace(' min', '').astype(int)\n",
        "\n",
        "        try:\n",
        "          # Combine the features into a single string\n",
        "          self.data['combined_features'] = self.data.apply(lambda row: f\"{row['Genre']} {row['Director']} {row['Star1']} {row['Star2']} {row['Star3']} {row['Star4']}\", axis=1)\n",
        "        except:\n",
        "          print(\"error reading the cols (Genre, Director...)\")\n",
        "\n",
        "\n",
        "    def _create_tfidf_matrix(self):\n",
        "        # Initialize the TF-IDF Vectorizer\n",
        "        tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "        # Fit and transform the data\n",
        "        self.tfidf_matrix = tfidf.fit_transform(self.data['combined_features'])\n",
        "\n",
        "        # Compute the cosine similarity matrix\n",
        "        self.cosine_sim = linear_kernel(self.tfidf_matrix, self.tfidf_matrix)\n",
        "\n",
        "        # Create a mapping of movie titles to indices\n",
        "        self.indices = pd.Series(self.data.index, index=self.data['Series_Title']).drop_duplicates()\n",
        "\n",
        "    def get_recommendations(self, title):\n",
        "        # Get the index of the movie that matches the title\n",
        "        idx = self.indices[title]\n",
        "\n",
        "        # Get the pairwise similarity scores of all movies with that movie\n",
        "        sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
        "\n",
        "        # Sort the movies based on the similarity scores\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Get the scores of the 10 most similar movies\n",
        "        sim_scores = sim_scores[1:11]\n",
        "\n",
        "        # Get the movie indices\n",
        "        movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "        # Return the top 10 most similar movies\n",
        "        return self.data['Series_Title'].iloc[movie_indices]\n",
        "\n",
        "    def get_weighted_recommendations(self, ratings):\n",
        "        total_sim_scores = {}\n",
        "\n",
        "        for movie, rating in ratings.items():\n",
        "            # Get the index of the movie that matches the title\n",
        "            idx = self.indices[movie]\n",
        "\n",
        "            # Get the pairwise similarity scores of all movies with that movie\n",
        "            sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
        "\n",
        "            for i, score in sim_scores:\n",
        "                if i in total_sim_scores:\n",
        "                    total_sim_scores[i] += score * rating\n",
        "                else:\n",
        "                    total_sim_scores[i] = score * rating\n",
        "\n",
        "        # Sort the movies based on the weighted similarity scores\n",
        "        sorted_sim_scores = sorted(total_sim_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Get the movie indices of the top recommendations, excluding already rated movies\n",
        "        recommended_movie_indices = [i[0] for i in sorted_sim_scores if self.data['Series_Title'].iloc[i[0]] not in ratings][:10]\n",
        "\n",
        "        # Return the top 10 recommendations\n",
        "        return self.data['Series_Title'].iloc[recommended_movie_indices]\n",
        "\n",
        "    def save(self, file_name):\n",
        "        with open(file_name, 'wb') as file:\n",
        "            pickle.dump(self, file)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file_name):\n",
        "        with open(file_name, 'rb') as file:\n",
        "            return pickle.load(file)\n"
      ],
      "metadata": {
        "id": "qGB9a3OUNWgJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of MovieRecommender with the data file\n",
        "recommender = MovieRecommender('imdb_top_1000.csv')\n",
        "\n",
        "# Save the recommender object to a file\n",
        "recommender.save('recommender.pkl')\n",
        "\n"
      ],
      "metadata": {
        "id": "pQ_wdm_tNpwc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the recommender object from a file\n",
        "loaded_recommender = MovieRecommender.load('recommender.pkl')\n",
        "\n",
        "# Assume you have a dictionary of personal ratings\n",
        "personal_ratings = {\n",
        "    'The Shawshank Redemption': 8,\n",
        "    'Inception': 10,\n",
        "    'The Dark Knight': 9,\n",
        "    'Dunkirk': 0,\n",
        "    'The Prestige': 10,\n",
        "    'Batman Begins':8,\n",
        "    'The Dark Knight Rises':10,\n",
        "    'Interstellar':10,\n",
        "    'Ford v Ferrari':8,\n",
        "    'American Psycho':7,\n",
        "    'The Machinist':5,\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "# Get recommendations based on your personal ratings\n",
        "recommendations = loaded_recommender.get_weighted_recommendations(personal_ratings)\n",
        "recommendations = list(recommendations)\n",
        "\n",
        "for i in recommendations:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxJxOZIMPF2f",
        "outputId": "f9110e29-ae10-4dc3-94fe-7f66310f5735"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3:10 to Yuma\n",
            "The Big Short\n",
            "Empire of the Sun\n",
            "The Fighter\n",
            "Memento\n",
            "The Man Who Would Be King\n",
            "Back to the Future Part II\n",
            "Back to the Future\n",
            "Children of Men\n",
            "Catch Me If You Can\n"
          ]
        }
      ]
    }
  ]
}